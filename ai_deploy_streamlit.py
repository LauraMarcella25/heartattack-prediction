# -*- coding: utf-8 -*-
"""AI deploy streamlit.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1uaRWsbG7cYTDsOZemsT5LVLTj59nBWmR
"""

import glob
import os
import pandas as pd
from PIL import Image
from google.colab import drive

drive.mount("/content/drive", force_remount=True)

base_path = "/content/drive/My Drive/Dataset_Heart_Attack"

import pandas as pd
from sklearn.preprocessing import LabelEncoder

df = pd.read_csv("/content/drive/My Drive/Dataset_Heart_Attack/heart_attack_prediction_indonesia.csv")

categorical_cols = [
    'gender', 'region', 'income_level', 'smoking_status',
    'alcohol_consumption', 'physical_activity', 'dietary_habits',
    'air_pollution_exposure', 'stress_level', 'EKG_results'
]

df_clean = df.copy()

label_encoders = {}
for col in categorical_cols:
    le = LabelEncoder()
    df_clean[col] = le.fit_transform(df_clean[col])

df_clean.to_csv("heart_attack_prediction_clean.csv", index=False)

df.info()

df[df.duplicated()]

def isi_null_dengan_modus(df, kolom):
    modus = df[kolom].mode()[0]
    df[kolom] = df[kolom].fillna(modus)

isi_null_dengan_modus(df, 'alcohol_consumption')

df.info()

df_test = df_clean.copy()

encoder = LabelEncoder()

df_desc = df_clean.describe()
df_desc

df.corr(numeric_only=True)

df_check = df_clean.copy()

duplicates_conflict = df_check.groupby(list(df_check.columns[:-1]))['heart_attack'].nunique()
conflict_rows = duplicates_conflict[duplicates_conflict > 1]


if len(conflict_rows) > 0:
    print("data tidak konsisten:")
    print(conflict_rows.head(10))

from sklearn.ensemble import RandomForestClassifier
import matplotlib.pyplot as plt
import numpy as np

X = df_clean.drop(columns=['heart_attack'])
y = df_clean['heart_attack']

rf = RandomForestClassifier(n_estimators=100, random_state=42)
rf.fit(X, y)

importances = rf.feature_importances_
indices = np.argsort(importances)[::-1]

plt.figure(figsize=(12,6))
plt.title("Feature Importance - Prediksi Serangan Jantung")
plt.bar(range(X.shape[1]), importances[indices], align="center")
plt.xticks(range(X.shape[1]), X.columns[indices], rotation=90)
plt.tight_layout()
plt.show()

import seaborn as sns
import matplotlib.pyplot as plt

df_fe = df_clean.copy()
df_fe = df_fe.drop(columns=["EKG_results", "region", "family_history", "dietary_habits", "participated_in_free_screening", "medication_usage","stress_level","air_pollution_exposure", "income_level"])

plt.figure(figsize=(12, 8))
sns.heatmap(df_fe.corr(), annot=False, cmap="coolwarm")
plt.title("Correlation Heatmap of Features")
plt.show()

corr_target = df_fe.corr()['heart_attack'].abs().sort_values(ascending=False)
print("\n--KORELASI TERHADAP HEART ATTACK--")
print(corr_target)

important_features = corr_target.index[1:6]

import seaborn as sns
for f in important_features:
    plt.figure(figsize=(6,4))
    sns.boxplot(data=df_fe, x='heart_attack', y=f)
    plt.title(f"Distribusi {f} terhadap Heart Attack")
    plt.show()

df_fe.drop(columns=['heart_attack']).hist(figsize=(16, 10), bins=20)
plt.suptitle("Histogram Semua Fitur dalam Dataset", y=2.00)
plt.show()

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

print(X)

"""FEATURE ENGINERING

"""

df_fe = df_clean.copy()
df_fe = df_fe.drop(columns=["EKG_results", "region", "family_history", "dietary_habits", "participated_in_free_screening", "medication_usage","stress_level","air_pollution_exposure", "income_level"])

X_fe = df_fe.drop(columns=["heart_attack"])
y_fe = df_fe["heart_attack"]

df_fe

"""XGBoost

"""

df_fe = df_clean.copy()
df_fe = df_fe.drop(columns=["EKG_results", "region", "family_history", "dietary_habits", "participated_in_free_screening", "medication_usage","stress_level","air_pollution_exposure", "income_level"])

X_fe = df_fe.drop(columns=["heart_attack"])
y_fe = df_fe["heart_attack"]

from sklearn.decomposition import PCA
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

pca = PCA(n_components=2)
X_pca = pca.fit_transform(X_fe)

# Scatter Plot PCA
plt.figure(figsize=(8, 6))
plt.scatter(X_pca[:, 0], X_pca[:, 1], c=y_fe, cmap="coolwarm")
plt.colorbar(label="Heart Attack")
plt.title("PCA Visualization - Heart Attack Dataset")
plt.xlabel("PC1")
plt.ylabel("PC2")
plt.show()

# Tabel kontribusi fitur terhadap PCA
pca_table = pd.DataFrame(
    pca.components_,
    index=["PC1", "PC2"],
    columns=X_fe.columns
)

print("\n===== PCA FEATURE CONTRIBUTION TABLE =====")
print(pca_table)

import numpy as np
from sklearn.model_selection import StratifiedKFold
from sklearn.metrics import classification_report
from xgboost import XGBClassifier


X_fe = df_fe.drop(columns=['heart_attack']).values
y_fe = df_fe['heart_attack'].values

RANDOM_SEED = 42
skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_SEED)

accs, macro_ps, macro_rs, macro_f1s = [], [], [], []
w_ps, w_rs, w_f1s = [], [], []

model = XGBClassifier(
        use_label_encoder=False,
        eval_metric='rmse',
        random_state=RANDOM_SEED
    )

for fold, (train_idx, test_idx) in enumerate(skf.split(X_fe, y_fe), start=1):
    X_train, X_test = X_fe[train_idx], X_fe[test_idx]
    y_train, y_test = y_fe[train_idx], y_fe[test_idx]

    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)

    print(f"\n=== Fold {fold} ===")
    print(classification_report(y_test, y_pred, digits=4))

    rep = classification_report(y_test, y_pred, output_dict=True)
    accs.append(rep["accuracy"])
    macro_ps.append(rep["macro avg"]["precision"])
    macro_rs.append(rep["macro avg"]["recall"])
    macro_f1s.append(rep["macro avg"]["f1-score"])
    w_ps.append(rep["weighted avg"]["precision"])
    w_rs.append(rep["weighted avg"]["recall"])
    w_f1s.append(rep["weighted avg"]["f1-score"])

print("\n=== Rata-rata Hasil Cross-Validation (XGBoost) ===")
print(f"Accuracy           : {np.mean(accs):.4f}")
print(f"Macro Precision    : {np.mean(macro_ps):.4f}")
print(f"Macro Recall       : {np.mean(macro_rs):.4f}")
print(f"Macro F1-score     : {np.mean(macro_f1s):.4f}")
print(f"Weighted Precision : {np.mean(w_ps):.4f}")
print(f"Weighted Recall    : {np.mean(w_rs):.4f}")
print(f"Weighted F1-score  : {np.mean(w_f1s):.4f}")

!kill -9 $(lsof -t -i:5000)

import pickle

dbfile = open('ModelHeartAttack.pkl', 'wb')
pickle.dump(model,dbfile)
dbfile.close()

from google.colab import drive
drive.mount('/content/drive')

dbfile = open('ModelHeartAttack.pkl', 'rb')
GMMModel = pickle.load(dbfile)